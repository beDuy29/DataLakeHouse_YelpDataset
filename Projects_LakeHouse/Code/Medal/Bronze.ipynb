{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import io\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buckets:\n",
      "bronze 2024-11-09 00:38:23.211000+00:00\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"6g\") \\\n",
    "    .config(\"spark.driver.memory\", \"3g\") \\\n",
    "    .config(\"spark.executor.memory\", \"3g\") \\\n",
    "    .appName(\"yelp_dataset\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "minio_client = Minio(\n",
    "    \"localhost:9000\",\n",
    "    access_key=\"sJ8IkEjav4gkDwjt2BxK\",\n",
    "    secret_key=\"atZpF6WhWSD0tH2vSxylDHYpdOWZ11zdnSZ87ca8\",\n",
    "    secure=False\n",
    ")\n",
    "\n",
    "try:\n",
    "    buckets = minio_client.list_buckets()\n",
    "    print(\"Buckets:\")\n",
    "    for bucket in buckets:\n",
    "        print(bucket.name, bucket.creation_date)\n",
    "except S3Error as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_url = 'mongodb://127.0.0.1/'\n",
    "bucket_yelp = \"yelp-dataset\"\n",
    "bucket_bronze = \"bronze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing collection: business\n",
      "Successfully processed collection: business\n",
      "Processing collection: checkin\n",
      "Successfully processed collection: checkin\n",
      "Processing collection: tip\n",
      "Successfully processed collection: tip\n",
      "Processing collection: user\n",
      "Successfully processed collection: user\n",
      "Processing collection: review\n",
      "Successfully processed collection: review\n"
     ]
    }
   ],
   "source": [
    "collections = ['business', 'checkin', 'tip', 'user', 'review']\n",
    "for collection in collections:\n",
    "    try:\n",
    "        print(f\"Processing collection: {collection}\")\n",
    "        bronze_df = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\") \\\n",
    "            .option('spark.mongodb.input.uri', mongo_url) \\\n",
    "            .option('spark.mongodb.input.database', 'YELP') \\\n",
    "            .option('spark.mongodb.input.collection', collection) \\\n",
    "            .load()\n",
    "            \n",
    "        bronze_df.repartition(1).write.format(\"parquet\").mode(\"append\").save(f\"./Parquet/{collection}\")\n",
    "        print(f\"Successfully processed collection: {collection}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing collection {collection}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "for collection in collections:\n",
    "    try:\n",
    "        for file_name in os.listdir(f'./Parquet/{collection}'):\n",
    "            if file_name.endswith(\".parquet\"):\n",
    "                print(f\"Processing collection: {collection}\")\n",
    "                os.rename(f'./Parquet/{collection}/{file_name}', f'./Parquet/{collection}/{collection}.parquet')\n",
    "                print(f\"Successfully renamed collection: {collection}\")\n",
    "    except Exception as e:\n",
    "            print(f\"Error renaming collection {collection}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pushed collection: business to minio\n",
      "Successfully pushed collection: checkin to minio\n",
      "Successfully pushed collection: tip to minio\n",
      "Successfully pushed collection: user to minio\n",
      "Successfully pushed collection: review to minio\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'bronze'\n",
    "\n",
    "for collection in collections:\n",
    "    try:\n",
    "        file = f'./Parquet/{collection}/{collection}.parquet'\n",
    "        obj = f'{collection}.parquet'\n",
    "        minio_client.fput_object(bucket_name, obj, file)\n",
    "        print(f\"Successfully pushed collection: {collection} to minio\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error pushing collection {collection} to minio: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
